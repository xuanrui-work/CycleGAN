{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "cont_run = ''\n",
    "# cont_run = './logs/run1'\n",
    "\n",
    "if not cont_run:\n",
    "    logdir = pathlib.Path('./logs')\n",
    "    i = 1\n",
    "    while (logdir/f'run{i}').exists():\n",
    "        i += 1\n",
    "    logdir = logdir/f'run{i}'\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    logdir = pathlib.Path(cont_run)\n",
    "    assert logdir.exists(), f'specified logdir \"{cont_run}\" does not exist!'\n",
    "\n",
    "writer = SummaryWriter(logdir)\n",
    "print(f'Logging to: {logdir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "hparams_file = ''\n",
    "# hparams_file = './hparams.yaml'\n",
    "\n",
    "if hparams_file:\n",
    "    with open(hparams_file) as f:\n",
    "        hparams = yaml.safe_load(f)\n",
    "else:\n",
    "    hparams = {\n",
    "        'image_size': [3, 32, 32],\n",
    "        'batch_size': 256,\n",
    "        'num_epochs': 100,\n",
    "        'val_every': 1,\n",
    "        # model hparams\n",
    "        'lr': 2.0e-4,\n",
    "        'betas': [0.5, 0.999],\n",
    "        'cyc_ABA': 10,\n",
    "        'cyc_BAB': 10,\n",
    "    }\n",
    "\n",
    "writer.add_hparams(\n",
    "    {k: v for k, v in hparams.items() if not isinstance(v, list)},\n",
    "    {}\n",
    ")\n",
    "writer.add_text('hparams', yaml.dump(hparams, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist2svhn import MNIST2SVHN\n",
    "\n",
    "input_shape = hparams['image_size']\n",
    "batch_size = hparams['batch_size']\n",
    "val_split = 0.2\n",
    "\n",
    "dataset = MNIST2SVHN(image_size=input_shape[1:], batch_size=batch_size, val_split=val_split)\n",
    "s_train_loader, s_val_loader, s_test_loader = dataset.get_loaders('src')\n",
    "t_train_loader, t_val_loader, t_test_loader = dataset.get_loaders('tgt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 50\n",
    "\n",
    "samples = next(iter(s_train_loader))\n",
    "xs, ys = samples[0][:num_samples], samples[1][:num_samples]\n",
    "\n",
    "print(xs.shape, ys.shape)\n",
    "grid_img = torchvision.utils.make_grid(xs, nrow=10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "samples = next(iter(t_train_loader))\n",
    "xt, yt = samples[0][:num_samples], samples[1][:num_samples]\n",
    "\n",
    "print(xt.shape, yt.shape)\n",
    "grid_img = torchvision.utils.make_grid(xt, nrow=10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.network import CycleGAN\n",
    "model = CycleGAN(hparams=hparams).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "print(summary(model, input_size=[\n",
    "    (batch_size, *input_shape), (batch_size, *input_shape)\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self, model, writer, device, batch_size=64):\n",
    "        self.model = model\n",
    "        self.writer = writer\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def vis_samples(self, samples, step, tag, mode='ab'):\n",
    "        outputs_all = {}\n",
    "\n",
    "        training = self.model.training\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(samples), self.batch_size):\n",
    "                x = torch.stack(samples[i:i+self.batch_size]).to(self.device)\n",
    "                if mode == 'ab':\n",
    "                    outputs = self.model(x_A=x, x_B=None)\n",
    "                elif mode == 'ba':\n",
    "                    outputs = self.model(x_A=None, x_B=x)\n",
    "                else:\n",
    "                    raise ValueError(f'invalid mode={mode}')\n",
    "                for k, v in outputs.items():\n",
    "                    if v is None:\n",
    "                        continue\n",
    "                    if k not in outputs_all:\n",
    "                        outputs_all[k] = []\n",
    "                    outputs_all[k] += [v]\n",
    "        \n",
    "        self.model.train(training)\n",
    "        \n",
    "        for k, v in outputs_all.items():\n",
    "            outputs_all[k] = torch.cat(v, dim=0)\n",
    "            writer.add_images(f'{tag}/{k}', outputs_all[k], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Visualizer(model, writer, device, batch_size=batch_size)\n",
    "n_vis = 50\n",
    "\n",
    "vxs_train = [s_train_loader.dataset[i][0] for i in range(n_vis)]\n",
    "vxt_train = [t_train_loader.dataset[i][0] for i in range(n_vis)]\n",
    "\n",
    "vxs_val = [s_val_loader.dataset[i][0] for i in range(n_vis)]\n",
    "vxt_val = [t_val_loader.dataset[i][0] for i in range(n_vis)]\n",
    "\n",
    "visualizer.vis_samples(vxs_train, 0, 'train', mode='ab')\n",
    "visualizer.vis_samples(vxt_train, 0, 'train', mode='ba')\n",
    "\n",
    "visualizer.vis_samples(vxs_val, 0, 'val', mode='ab')\n",
    "visualizer.vis_samples(vxt_val, 0, 'val', mode='ba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader_s, loader_t):\n",
    "    loss_dict = {}\n",
    "    len_loader = min(len(loader_s), len(loader_t))\n",
    "\n",
    "    training = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (xs, ys), (xt, yt) in zip(loader_s, loader_t):\n",
    "            if xs.shape[0] != xt.shape[0]:\n",
    "                continue\n",
    "            N = xs.shape[0]\n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            xt, yt = xt.to(device), yt.to(device)\n",
    "\n",
    "            outputs, loss_dict1 = model.optimize_params(xs, xt, backward=False)\n",
    "            for k, v in loss_dict1.items():\n",
    "                loss_dict[k] = loss_dict.get(k, 0) + v*N\n",
    "    \n",
    "    model.train(training)\n",
    "\n",
    "    for k in loss_dict:\n",
    "        loss_dict[k] /= len_loader*batch_size\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cont_run:\n",
    "    model.load_state_dict(torch.load(logdir/'last_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = hparams['num_epochs']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['lr'])\n",
    "\n",
    "validate_every = hparams['val_every']\n",
    "\n",
    "model.hparams = hparams\n",
    "model.train()\n",
    "step = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "len_loader = min(len(s_train_loader), len(t_train_loader))\n",
    "\n",
    "print(f'len(s_train_loader): {len(s_train_loader)}')\n",
    "print(f'len(t_train_loader): {len(t_train_loader)}')\n",
    "print(f'len_loader: {len_loader}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # for (xs, ys), (xt, yt) in tqdm(\n",
    "    #     zip(s_train_loader, t_train_loader), total=len_loader, leave=False\n",
    "    # ):\n",
    "    for (xs, ys), (xt, yt) in zip(s_train_loader, t_train_loader):\n",
    "        if xs.shape[0] != xt.shape[0]:\n",
    "            continue\n",
    "        N = xs.shape[0]\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "        xt, yt = xt.to(device), yt.to(device)\n",
    "\n",
    "        outputs, loss_dict = model.optimize_params(xs, xt)\n",
    "        step += 1\n",
    "        for k, v in loss_dict.items():\n",
    "            writer.add_scalar(f'train/{k}', v.item(), step)\n",
    "    \n",
    "    if epoch % validate_every == 0:\n",
    "        val_loss_dict = evaluate(model, s_val_loader, t_val_loader)\n",
    "        for k, v in val_loss_dict.items():\n",
    "            writer.add_scalar(f'val/{k}', v.item(), step)\n",
    "        \n",
    "        # visualize\n",
    "        visualizer.vis_samples(vxs_train, step, 'train', mode='ab')\n",
    "        visualizer.vis_samples(vxt_train, step, 'train', mode='ba')\n",
    "\n",
    "        visualizer.vis_samples(vxs_val, step, 'val', mode='ab')\n",
    "        visualizer.vis_samples(vxt_val, step, 'val', mode='ba')\n",
    "\n",
    "        # if val_loss_dict['loss'] < best_val_loss:\n",
    "        #     best_val_loss = val_loss_dict['loss']\n",
    "        #     torch.save(model.state_dict(), logdir/'best_model.pth')\n",
    "\n",
    "torch.save(model.state_dict(), logdir/'last_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(logdir/'last_model.pth'))\n",
    "loss_dict = evaluate(model, s_test_loader, t_test_loader)\n",
    "from pprint import pprint\n",
    "pprint(loss_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect domain variant vs invariant reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(logdir/'last_model.pth'))\n",
    "visualizer.vis_samples(vxs_val, step, 'vis', mode='ab')\n",
    "visualizer.vis_samples(vxt_val, step, 'vis', mode='ba')\n",
    "\n",
    "visualizer.vis_samples(vxs_val, step, 'vis', mode='ab')\n",
    "visualizer.vis_samples(vxt_val, step, 'vis', mode='ba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
